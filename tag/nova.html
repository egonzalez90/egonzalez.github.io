<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>OpenStack Stuff | articles tagged "nova"</title>
    <link rel="shortcut icon" type="image/png" href="https://egonzalez90.github.io/favicon.png">
    <link rel="shortcut icon" type="image/x-icon" href="https://egonzalez90.github.io/favicon.ico">
    <link href="https://egonzalez90.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="OpenStack Stuff Full Atom Feed" />
    <link rel="stylesheet" href="https://egonzalez90.github.io/theme/css/screen.css" type="text/css" />
    <link rel="stylesheet" href="https://egonzalez90.github.io/theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="https://egonzalez90.github.io/theme/css/print.css" type="text/css" media="print" />
    <meta name="generator" content="Pelican" />
    <meta name="description" content="" />
    <meta name="author" content="Eduardo Gonzalez" />
</head>
<body>
    <header>
        <nav>
            <ul>
                <li class="ephemeral selected"><a href="https://egonzalez90.github.io/tag/nova.html">nova</a></li>
                <li><a href="https://egonzalez90.github.io/">Home</a></li>
                <li><a href="https://docs.openstack.org">OpenStack</a></li>
                <li><a href="https://www.linkedin.com/in/eduardogonzalezgutierrez">Linkedin</a></li>
                <li><a href="https://github.com/egonzalez90">Github</a></li>
                <li><a href="https://egonzalez90.github.io/archives">Archives</a></li>
            </ul>
        </nav>
        <div class="header_box">
            <h1><a href="https://egonzalez90.github.io/">OpenStack Stuff</a></h1>
        </div>
    </header>
    <div id="wrapper">
        <div id="content">            <h4 class="date">Mar 02, 2016</h4>

            <article class="post">
                <h2 class="title">
                    <a href="https://egonzalez90.github.io/nova-vnc-flows-under-the-hood.html" rel="bookmark" title="Permanent Link to &quot;Nova VNC flows under the hood&quot;">Nova VNC flows under the hood</a>
                </h2>

                
                

                <p>Most OpenStack deployments has a VNC console implemented with
nova-novncproxy. This service gives the final user the ability to log
into their instances in a web based method through a browser.</p>
<p>At this post i'm going to show how a vnc console request works under the
hood while using the following command or lauching a vnc session through
Horizon.</p>
<div class="highlight"><pre><span></span># nova get-vnc-console INSTANCE novnc
</pre></div>


<p>First of all, a user connects to NOVA and issues a VNC console request
for an instance. Nova API needs to validate the user issuing an
authentication request to keystone.<br>
The user receives a token with nova's endpoint URL in the catalog, with
that endpoint and the token, the user makes a request against nova
calling for a VNC session.</p>
<div class="highlight"><pre><span></span>GET http://192.168.200.208:5000/v2.0 -H &quot;Accept: application/json&quot; -H
</pre></div>


<p>"User-Agent: python-keystoneclient"</p>
<div class="highlight"><pre><span></span>GET http://192.168.200.208:8774/v2/ -H &quot;User-Agent: python-novaclient&quot; -H
</pre></div>


<p>"Accept: application/json" -H "X-Auth-Token: {SHA1}3b6262df9eaba5da33c1004805187806322201f1"</p>
<p>If a name instead of an instance ID is used in the request, Nova need to
check his database to match that name with his corresponding ID, as we
can see in the following request.</p>
<div class="highlight"><pre><span></span>GET http://192.168.200.208:8774/v2/ee84411cdb8148d28674b129ef482f31/servers?name=test1
</pre></div>


<p>-H "User-Agent: python-novaclient" -H "Accept: application/json" <br>
   -H "X-Auth-Token: {SHA1}3b6262df9eaba5da33c1004805187806322201f1"</p>
<div class="highlight"><pre><span></span>RESP BODY: {&quot;servers&quot;: [{&quot;id&quot;: &quot;9165dbda-f54e-4186-b2cb-e6ca05ac53ee&quot;,
</pre></div>


<p>"links": [{"href": "http://192.168.200.208:8774/v2/ee84411cdb8148d28674b129ef482f31/servers/9165dbda-f54e-4186-b2cb-e6ca05ac53ee", "rel": "self"},<br>
    {"href": "http://192.168.200.208:8774/ee84411cdb8148d28674b129ef482f31/servers/9165dbda-f54e-4186-b2cb-e6ca05ac53ee", <br>
   "rel": "bookmark"}], "name": "test1"}]}</p>
<p>Once the ID is matched with the name, Nova check information about the
instance (I thought it was to validate if is in ACTIVE status, but i
realized that even when is in STOPPED status the request is made it
anyway).</p>
<div class="highlight"><pre><span></span>GET http://192.168.200.208:8774/v2/ee84411cdb8148d28674b129ef482f31/servers/9165dbda-f54e-4186-b2cb-e6ca05ac53ee  
-H &quot;User-Agent: python-novaclient&quot; -H &quot;Accept: application/json&quot;   
-H &quot;X-Auth-Token: {SHA1}3b6262df9eaba5da33c1004805187806322201f1&quot;

RESP BODY: {&quot;server&quot;: {&quot;status&quot;: &quot;ACTIVE&quot;, &quot;updated&quot;: &quot;2016-03-02T17:28:45Z&quot;, &quot;hostId&quot;: &quot;ca3a874dcad9079fcc6a0b10b0e2efaa394bc66b5335197fdd9c2498&quot;, &quot;OS-EXT-SRV-ATTR:host&quot;: &quot;liberty&quot;, &quot;addresses&quot;: {&quot;private&quot;: [{&quot;OS-EXT-IPS-MAC:mac_addr&quot;: &quot;fa:16:3e:aa:1c:32&quot;, &quot;version&quot;: 4, &quot;addr&quot;: &quot;10.0.0.6&quot;, &quot;OS-EXT-IPS:type&quot;: &quot;fixed&quot;}]}, &quot;links&quot;: [{&quot;href&quot;: &quot;http://192.168.200.208:8774/v2/ee84411cdb8148d28674b129ef482f31/servers/9165dbda-f54e-4186-b2cb-e6ca05ac53ee&quot;, &quot;rel&quot;: &quot;self&quot;}, {&quot;href&quot;: &quot;http://192.168.200.208:8774/ee84411cdb8148d28674b129ef482f31/servers/9165dbda-f54e-4186-b2cb-e6ca05ac53ee&quot;, &quot;rel&quot;: &quot;bookmark&quot;}], &quot;key_name&quot;: null, &quot;image&quot;: {&quot;id&quot;: &quot;bf31eadd-c5f4-40f8-9ddb-30f688ca5e5f&quot;, &quot;links&quot;: [{&quot;href&quot;: &quot;http://192.168.200.208:8774/ee84411cdb8148d28674b129ef482f31/images/bf31eadd-c5f4-40f8-9ddb-30f688ca5e5f&quot;, &quot;rel&quot;: &quot;bookmark&quot;}]}, &quot;OS-EXT-STS:task_state&quot;: null, &quot;OS-EXT-STS:vm_state&quot;: &quot;active&quot;, &quot;OS-EXT-SRV-ATTR:instance_name&quot;: &quot;instance-0000000a&quot;, &quot;OS-SRV-USG:launched_at&quot;: &quot;2016-03-02T17:28:45.000000&quot;, &quot;OS-EXT-SRV-ATTR:hypervisor_hostname&quot;: &quot;liberty&quot;, &quot;flavor&quot;: {&quot;id&quot;: &quot;1&quot;, &quot;links&quot;: [{&quot;href&quot;: &quot;http://192.168.200.208:8774/ee84411cdb8148d28674b129ef482f31/flavors/1&quot;, &quot;rel&quot;: &quot;bookmark&quot;}]}, &quot;id&quot;: &quot;9165dbda-f54e-4186-b2cb-e6ca05ac53ee&quot;, &quot;security_groups&quot;: [{&quot;name&quot;: &quot;default&quot;}], &quot;OS-SRV-USG:terminated_at&quot;: null, &quot;OS-EXT-AZ:availability_zone&quot;: &quot;nova&quot;, &quot;user_id&quot;: &quot;d9164a323be649c0a8c5c80fdd5bd585&quot;, &quot;name&quot;: &quot;test1&quot;, &quot;created&quot;: &quot;2016-03-02T17:28:34Z&quot;, &quot;tenant_id&quot;: &quot;ee84411cdb8148d28674b129ef482f31&quot;, &quot;OS-DCF:diskConfig&quot;: &quot;MANUAL&quot;, &quot;os-extended-volumes:volumes_attached&quot;: [], &quot;accessIPv4&quot;: &quot;&quot;, &quot;accessIPv6&quot;: &quot;&quot;, &quot;progress&quot;: 0, &quot;OS-EXT-STS:power_state&quot;: 1, &quot;config_drive&quot;: &quot;&quot;, &quot;metadata&quot;: {}}}
</pre></div>


<p>When we get the information, nova-api POST a request to nova-consoleauth
for a VNC console.</p>
<div class="highlight"><pre><span></span>POST http://192.168.200.208:8774/v2/ee84411cdb8148d28674b129ef482f31/servers/9165dbda-f54e-4186-b2cb-e6ca05ac53ee/action
</pre></div>


<p>-H "User-Agent: python-novaclient" -H "Content-Type: application/json" <br>
   -H "Accept: application/json" -H "X-Auth-Token: {SHA1}3b6262df9eaba5da33c1004805187806322201f1"<br>
   -d '{"os-getVNCConsole": {"type": "novnc"}}'</p>
<div class="highlight"><pre><span></span>DEBUG nova.api.openstack.wsgi [req-2201b9d6-5711-46d3-ac4d-669094f07527
</pre></div>


<p>d9164a323be649c0a8c5c80fdd5bd585 ee84411cdb8148d28674b129ef482f31 - - -] <br>
   Action: 'action', calling method: , body: {"os-getVNCConsole": {"type": "novnc"}} <br>
   _process_stack /usr/lib/python2.7/site-packages/nova/api/openstack/wsgi.py:789</p>
<p>Nova-consoleauth receives the console request and create an access URL
while generates a temporary token for the vnc console.</p>
<div class="highlight"><pre><span></span>INFO nova.consoleauth.manager [req-d4def6f9-1ab9-4626-b6a8-d81643ea5eb4 d9164a323be649c0a8c5c80fdd5bd585 ee84411cdb8148d28674b129ef482f31 - - -]
</pre></div>


<p>Received Token: 3dfcd011-28f1-4cf3-8f5c-8cd18de4560e, <br>
   {'instance_uuid': u'9165dbda-f54e-4186-b2cb-e6ca05ac53ee', <br>
   'access_url': u'http://192.168.200.208:6080/vnc_auto.html?token=3dfcd011-28f1-4cf3-8f5c-8cd18de4560e',<br>
    'token': u'3dfcd011-28f1-4cf3-8f5c-8cd18de4560e', 'last_activity_at': 1456940028.356214, <br>
   'internal_access_path': None, 'console_type': u'novnc', 'host': u'liberty', 'port': u'5900'}</p>
<p>Nova-consoleauth answer to nova-api who also answers to the user with an
access URL.<br>
This URL got the following content on it:</p>
<ul>
<li>HTTP or HTTPS connection to nova-novncproxy IP</li>
<li>Nova-novncproxy port</li>
<li>A token to validate the VNC connection</li>
</ul>
<!-- -->

<div class="highlight"><pre><span></span>RESP BODY: {&quot;console&quot;: {&quot;url&quot;: &quot;http://192.168.200.208:6080/vnc_auto.html?token=3dfcd011-28f1-4cf3-8f5c-8cd18de4560e&quot;, &quot;type&quot;: &quot;novnc&quot;}}

+-------+--------------------------------------------------------------------------------------+
| Type  | Url                                                                                  |
+-------+--------------------------------------------------------------------------------------+
| novnc | http://192.168.200.208:6080/vnc_auto.html?token=3dfcd011-28f1-4cf3-8f5c-8cd18de4560e |
+-------+--------------------------------------------------------------------------------------+
</pre></div>


<p>Until now, nova-novncproxy service can be stopped or isn't used at all,
is at this point the when proxy server enter into the game.<br>
The user connects through a web browser to the nova-novncproxy's URL
provided by nova before.</p>
<div class="highlight"><pre><span></span>DEBUG nova.console.websocketproxy [-] 192.168.200.1:
</pre></div>


<p>new handler Process vmsg /usr/lib/python2.7/site-packages/websockify/websocket.py:828</p>
<p>Nova-vncproxy validate the issued token with the URL against
nova-consoleauth.</p>
<div class="highlight"><pre><span></span>nova.consoleauth.manager [req-399c7b58-700a-4779-b215-b12d10056813 - - - - -]
</pre></div>


<p>Checking Token: 3dfcd011-28f1-4cf3-8f5c-8cd18de4560e, True</p>
<p>When the token is validated, nova-novncproxy maps compute's node private
IP (at this case port 5900) with the nova-novncproxy public IP(6080
port).</p>
<div class="highlight"><pre><span></span>INFO nova.console.websocketproxy [req-399c7b58-700a-4779-b215-b12d10056813 - - - - -]  
  7: connect info: {u&#39;instance_uuid&#39;: u&#39;9165dbda-f54e-4186-b2cb-e6ca05ac53ee&#39;, u&#39;
</pre></div>


<p>internal_access_path': None, u'last_activity_at': 1456940028.356214, <br>
   u'console_type': u'novnc', u'host': u'liberty', u'token': u'3dfcd011-28f1-4cf3-8f5c-8cd18de4560e', <br>
   u'access_url': u'http://192.168.200.208:6080/vnc_auto.html?token=3dfcd011-28f1-4cf3-8f5c-8cd18de4560e'<br>
   , u'port': u'5900'}</p>
<p>We can see how the python novncproxy process binds both IPs/port.</p>
<div class="highlight"><pre><span></span># ps aux | grep vnc
nova     14840  1.2  0.7 362096 41000 ?        S    18:53   0:14 /usr/bin/python2 /usr/bin/nova-novncproxy --web /usr/share/novnc/

# netstat -putona | grep 14840
tcp        0      0 192.168.200.208:6080    192.168.200.1:59918     ESTABLISHED 14840/python2        keepalive (3,13/0/0)
tcp        0      0 192.168.122.73:57764    192.168.122.73:5900     ESTABLISHED 14840/python2        keepalive (3,13/0/0)
</pre></div>


<p>Nova-novncproxy starts the connection between the instance and user's
browser session.</p>
<div class="highlight"><pre><span></span>INFO nova.console.websocketproxy [req-399c7b58-700a-4779-b215-b12d10056813 - - - - -]  
  7: connecting to: liberty:5900
</pre></div>


<p>Libvirt connects a vnc console into the instance, as we can see at the
xml provided by virsh command.<br>
Also, port 5900 now is binded at qemu-kvm process.</p>
<div class="highlight"><pre><span></span># virsh dumpxml 2
...
<span class="nt">&lt;graphics</span> <span class="na">type=</span><span class="s">&#39;vnc&#39;</span> <span class="na">port=</span><span class="s">&#39;5900&#39;</span> <span class="na">autoport=</span><span class="s">&#39;yes&#39;</span> <span class="na">listen=</span><span class="s">&#39;0.0.0.0&#39;</span> <span class="na">keymap=</span><span class="s">&#39;en-us&#39;</span><span class="nt">&gt;</span>
     <span class="nt">&lt;listen</span> <span class="na">type=</span><span class="s">&#39;address&#39;</span> <span class="na">address=</span><span class="s">&#39;0.0.0.0&#39;</span><span class="nt">/&gt;</span>
   <span class="nt">&lt;/graphics&gt;</span>
...

# netstat -putona | grep 5900
tcp        0      0 0.0.0.0:5900            0.0.0.0:*               LISTEN      5910/qemu-kvm        off (0.00/0/0)
tcp        0      0 192.168.122.73:5900     192.168.122.73:57702    ESTABLISHED 5910/qemu-kvm        off (0.00/0/0)
tcp        0      0 192.168.122.73:57702    192.168.122.73:5900     ESTABLISHED 11118/python2        keepalive (1,92/0/0)
</pre></div>


<p>Nova-novncproxy keeps the connection alive until browser session ends.</p>
<div class="highlight"><pre><span></span>DEBUG nova.console.websocketproxy [-]
</pre></div>


<p>Reaing zombies, active child count is 1 vmsg /usr/lib/python2.7/site-packages/websockify/websocket.py:828</p>
<p>When a token is not valid while authenticating against nova-consoleauth,
we can see a message like the following.</p>
<div class="highlight"><pre><span></span>INFO nova.console.websocketproxy [req-9164b32d-3ce1-441b-82c7-6c23c9a354d0 - - - - -]
</pre></div>


<p>handler exception: The token '3dfcd011-28f1-4cf3-8f5c-8cd18de4560e' is invalid or has expired</p>
<p>Regards.<br>
Eduardo Gonzalez</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="https://egonzalez90.github.io/nova-vnc-flows-under-the-hood.html">posted at 22:26</a>
                    &nbsp;&middot;&nbsp;<a href="https://egonzalez90.github.io/category/openstack.html" rel="tag">OpenStack</a>
                    &nbsp;&middot;
                    &nbsp;<a href="https://egonzalez90.github.io/tag/auth.html" class="tags">auth</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/console.html" class="tags">console</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/consoleauth.html" class="tags">consoleauth</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/flow.html" class="tags">flow</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/flows.html" class="tags">flows</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/how.html" class="tags">how</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/internal.html" class="tags">internal</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/liberty.html" class="tags">liberty</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/nova.html" class="tags selected">nova</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/novnc.html" class="tags">novnc</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/novncproxy.html" class="tags">novncproxy</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/openstack.html" class="tags">openstack</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/traffic.html" class="tags">traffic</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/vnc.html" class="tags">vnc</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/works.html" class="tags">works</a>
                </div>
		<a href="https://egonzalez90.github.io/nova-vnc-flows-under-the-hood.html#disqus_thread">Click to read and post comments</a>
            </article>            <h4 class="date">Feb 15, 2016</h4>

            <article class="post">
                <h2 class="title">
                    <a href="https://egonzalez90.github.io/working-with-affinityanti-affinity-groups-openstack.html" rel="bookmark" title="Permanent Link to &quot;Working with affinity/anti-affinity groups OpenStack&quot;">Working with affinity/anti-affinity groups OpenStack</a>
                </h2>

                
                

                <p>In a previous post, you learned how to segregate resources with
<a href="http://egonzalez.org/openstack-segregation-with-availability-zones-and-host-aggregates/">Availability Zones and Host
Aggregates</a>,
those methods allows the end user to specify where and on which types of
resources their instances should be running.</p>
<p>At this post, you will learn how specify to nova where nova-scheduler
should schedule your instances based on two policies. These policies
define if instances should share the same hypervisor (affinity rule) or
if not depending of user needs(anti-affinity rule).</p>
<p>First, you need to modify nova.conf and allow nova-scheduler to filter
based on affinity rules. Add <code>ServerGroupAntiAffinityFilter</code> and
<code>ServerGroupAffinityFilter</code> filters to scheduler default filter option.</p>
<div class="highlight"><pre><span></span># vi /etc/nova.conf

scheduler_default_filters=RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,CoreFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter
</pre></div>


<p>Restart nova-scheduler to apply changes</p>
<div class="highlight"><pre><span></span>systemctl restart openstack-nova-scheduler
</pre></div>


<p>Once nova-scheduler has been restarted, we can create a group of servers
based on affinity policy (All instances at this group will be launched
in the same hypervisor)</p>
<div class="highlight"><pre><span></span>nova server-group-create instancestogethergroup affinity
+--------------------------------------+------------------------+---------------+---------+----------+
| Id                                   | Name                   | Policies      | Members | Metadata |
+--------------------------------------+------------------------+---------------+---------+----------+
| 27abe662-c37e-431c-9715-0d2137fc5519 | instancestogethergroup | [u&#39;affinity&#39;] | []      | {}       |
+--------------------------------------+------------------------+---------------+---------+----------+
</pre></div>


<p>Now create two instances, add <code>--hint group=GROUP-ID</code> option to specify
the group where instances will be members.</p>
<div class="highlight"><pre><span></span>nova boot --image a6d7a606-f725-480a-9b1b-7b3ae39b93d4 --flavor m1.tiny --nic net-id=154da7a8-fa49-415e-9d35-c840b144a8df --hint group=27abe662-c37e-431c-9715-0d2137fc5519 affinity1
nova boot --image a6d7a606-f725-480a-9b1b-7b3ae39b93d4 --flavor m1.tiny --nic net-id=154da7a8-fa49-415e-9d35-c840b144a8df --hint group=27abe662-c37e-431c-9715-0d2137fc5519 affinity2
</pre></div>


<p>Ensure the instances are properly mapped to the group.</p>
<div class="highlight"><pre><span></span>nova server-group-get 27abe662-c37e-431c-9715-0d2137fc5519 
+--------------------------------------+------------------------+---------------+------------------------------------------------------------------------------------+----------+
| Id                                   | Name                   | Policies      | Members                                                                            | Metadata |
+--------------------------------------+------------------------+---------------+------------------------------------------------------------------------------------+----------+
| 27abe662-c37e-431c-9715-0d2137fc5519 | instancestogethergroup | [u&#39;affinity&#39;] | [u&#39;b8b72a0a-c981-430e-a909-13d23d928655&#39;, u&#39;8affefff-0072-47e3-8d11-2ddf26e48b82&#39;] | {}       |
+--------------------------------------+------------------------+---------------+------------------------------------------------------------------------------------+----------+
</pre></div>


<p>Once instances are running, ensure they share the same hypervisor as we
specify in the affinity policy.</p>
<div class="highlight"><pre><span></span># nova show affinity1 | grep hypervisor_hostname
| OS-EXT-SRV-ATTR:hypervisor_hostname  | compute2az
# nova show affinity2 | grep hypervisor_hostname
| OS-EXT-SRV-ATTR:hypervisor_hostname  | compute2az
</pre></div>


<p>Now we create an anti-affinity policy based group.</p>
<div class="highlight"><pre><span></span>nova server-group-create farinstancesgroup anti-affinity
+--------------------------------------+-------------------+--------------------+---------+----------+
| Id                                   | Name              | Policies           | Members | Metadata |
+--------------------------------------+-------------------+--------------------+---------+----------+
| 988a9fd2-3a97-481e-b083-fee36b33009d | farinstancesgroup | [u&#39;anti-affinity&#39;] | []      | {}       |
+--------------------------------------+-------------------+--------------------+---------+----------+
</pre></div>


<p>Launch two instances and attach them to the anti-affinity group.</p>
<div class="highlight"><pre><span></span>nova boot --image a6d7a606-f725-480a-9b1b-7b3ae39b93d4 --flavor m1.tiny --nic net-id=154da7a8-fa49-415e-9d35-c840b144a8df --hint group=988a9fd2-3a97-481e-b083-fee36b33009d anti-affinity1
nova boot --image a6d7a606-f725-480a-9b1b-7b3ae39b93d4 --flavor m1.tiny --nic net-id=154da7a8-fa49-415e-9d35-c840b144a8df --hint group=988a9fd2-3a97-481e-b083-fee36b33009d anti-affinity2
</pre></div>


<p>Ensure the instances are in the anti-affinity group</p>
<div class="highlight"><pre><span></span>nova server-group-get 988a9fd2-3a97-481e-b083-fee36b33009d 
+--------------------------------------+-------------------+--------------------+------------------------------------------------------------------------------------+----------+
| Id                                   | Name              | Policies           | Members                                                                            | Metadata |
+--------------------------------------+-------------------+--------------------+------------------------------------------------------------------------------------+----------+
| 988a9fd2-3a97-481e-b083-fee36b33009d | farinstancesgroup | [u&#39;anti-affinity&#39;] | [u&#39;cfb45193-9a7c-436f-ac2d-59a7a9a854ae&#39;, u&#39;25dc8671-0c9a-4774-90cf-7394380f91ef&#39;] | {}       |
+--------------------------------------+-------------------+--------------------+------------------------------------------------------------------------------------+----------+
</pre></div>


<p>Once instances are running, ensure they are in different hypervisors as
we specify in the anti-affinity policy.</p>
<div class="highlight"><pre><span></span># nova show anti-affinity1 | grep hypervisor_hostname
| OS-EXT-SRV-ATTR:hypervisor_hostname  | compute2az
# nova show anti-affinity2 | grep hypervisor_hostname
| OS-EXT-SRV-ATTR:hypervisor_hostname  | compute1az
</pre></div>


<p>Regards, Eduardo Gonzalez</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="https://egonzalez90.github.io/working-with-affinityanti-affinity-groups-openstack.html">posted at 21:05</a>
                    &nbsp;&middot;&nbsp;<a href="https://egonzalez90.github.io/category/openstack.html" rel="tag">OpenStack</a>
                    &nbsp;&middot;
                    &nbsp;<a href="https://egonzalez90.github.io/tag/affinity.html" class="tags">affinity</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/anti-affinity.html" class="tags">anti-affinity</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/filter.html" class="tags">filter</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/groups.html" class="tags">groups</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/liberty.html" class="tags">liberty</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/nova.html" class="tags selected">nova</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/openstack.html" class="tags">openstack</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/rdo.html" class="tags">rdo</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/scheduler.html" class="tags">scheduler</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/servergroupaffinityfilter.html" class="tags">ServerGroupAffinityFilter</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/servergroupantiaffinityfilter.html" class="tags">ServerGroupAntiAffinityFilter</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/working.html" class="tags">working</a>
                </div>
		<a href="https://egonzalez90.github.io/working-with-affinityanti-affinity-groups-openstack.html#disqus_thread">Click to read and post comments</a>
            </article>            <h4 class="date">Jan 14, 2016</h4>

            <article class="post">
                <h2 class="title">
                    <a href="https://egonzalez90.github.io/openstack-segregation-with-availability-zones-and-host-aggregates.html" rel="bookmark" title="Permanent Link to &quot;OpenStack segregation with Availability Zones and Host Aggregates&quot;">OpenStack segregation with Availability Zones and Host Aggregates</a>
                </h2>

                
                

                <p>When a new OpenStack cloud born, usually all servers run over the same
hardware and specifications, often, all servers are in the same
building, room, rack, even a chassis when the cloud is in the first
growth paces.</p>
<p>After a while, workloads increase and the current hardware is not enough
to process that workloads. At this point, your hardware is old and new
hardware is bought. This hardware has different storage disks, CPU, RAM
and so on. You passed from 10's of servers to 100's. DataCenter racks,
rooms and buildings are too small and the growing cloud needs redundancy
between cities or countries.</p>
<p>OpenStack offers a few solutions for that purpose, called Regions,
Cells, Availability Zones and Host Aggregates.<br>
Now, we are going to focus on Availability Zones and Host Aggregates,
which are the way to segregate computational workloads.</p>
<ul>
<li>Host Aggregates:<ul>
<li>Host Aggregates represent a logical set of
    properties/characteristics a group of hosts owns in the form of
    metadata. Imagine some of your servers have SSD disks and the
    other ones SATA, you can map those properties SSD/SATA to a
    group of hosts, when a image or flavor with the metaparameter
    associated is launched, Nova Scheduler will filter the available
    hosts with the meta parameter value and boot the instance on
    hosts with the desired property. Host Aggregates are managed by
    OpenStack admins.</li>
</ul>
</li>
<li>Availability Zones<ul>
<li>Availability Zones represent a logical partition of the
    infrastructure(not necessary but is the common use case) in the
    form of racks, rooms, buildings, etc. Customers can launch
    instances in the desired Availability Zone.</li>
</ul>
</li>
</ul>
<p>Usually, Host Aggregates are mapped to Availability Zones allowing
customers to use the desired set of hardware or characteristics to boot
instances.</p>
<p>At the end of this guide you will know how to:</p>
<ol>
<li>Create Availability Zones and Host Aggregates.</li>
<li>Adding hosts to Host Aggregates and Availability Zones.</li>
<li>Launch instances directly to Availability Zones.</li>
<li>Configure nova scheduler for Host Aggregates usage.</li>
<li>Configure Images and Flavors for scheduling to Host Aggregates.</li>
<li>Launch instances based on flavors and image parameters.</li>
</ol>
<p>Let's start: \00/</p>
<p>Create two Host Aggregate called <code>"az1-ag"/"az2-ag"</code>, this command also,
will create two Availability Zones called <code>"az1"/"az2"</code>.<br>
By default, when a Host Aggregate is created with an Availability Zone,
a metadata key called <code>"availability_zone=NAME_OF_AZ</code>" will be created.</p>
<div class="highlight"><pre><span></span># nova aggregate-create az1-ag az1
+----+--------+-------------------+-------+-------------------------+
| Id | Name   | Availability Zone | Hosts | Metadata                |
+----+--------+-------------------+-------+-------------------------+
| 2  | az1-ag | az1               |       | &#39;availability_zone=az1&#39; |
+----+--------+-------------------+-------+-------------------------+
# nova aggregate-create az2-ag az2
+----+--------+-------------------+-------+-------------------------+
| Id | Name   | Availability Zone | Hosts | Metadata                |
+----+--------+-------------------+-------+-------------------------+
| 3  | az2-ag | az2               |       | &#39;availability_zone=az2&#39; |
+----+--------+-------------------+-------+-------------------------+
</pre></div>


<p>Add one or more compute nodes to Host Aggregates.</p>
<div class="highlight"><pre><span></span># nova aggregate-add-host 2 compute1az
Host compute1az has been successfully added for aggregate 2 
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 2  | az1-ag | az1               | &#39;compute1az&#39; | &#39;availability_zone=az1&#39; |
+----+--------+-------------------+--------------+-------------------------+
# nova aggregate-add-host 3 compute2az
Host compute2az has been successfully added for aggregate 3 
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 3  | az2-ag | az2               | &#39;compute2az&#39; | &#39;availability_zone=az2&#39; |
+----+--------+-------------------+--------------+-------------------------+
</pre></div>


<p>Details about a Host Aggregate can be reviewed with:</p>
<div class="highlight"><pre><span></span># nova aggregate-details az1-ag
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 2  | az1-ag | az1               | &#39;compute1az&#39; | &#39;availability_zone=az1&#39; |
+----+--------+-------------------+--------------+-------------------------+
# nova aggregate-details az2-ag
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 3  | az2-ag | az2               | &#39;compute2az&#39; | &#39;availability_zone=az2&#39; |
+----+--------+-------------------+--------------+-------------------------+
</pre></div>


<p>List Availability Zones and check status.</p>
<div class="highlight"><pre><span></span><span class="c1"># nova availability-zone-list</span>
<span class="s s-Atom">+-----------------------+----------------------------------------+</span>
<span class="p">|</span> <span class="nv">Name</span>                  <span class="p">|</span> <span class="nv">Status</span>                                 <span class="p">|</span>
<span class="s s-Atom">+-----------------------+----------------------------------------+</span>
<span class="p">|</span> <span class="s s-Atom">internal</span>              <span class="p">|</span> <span class="s s-Atom">available</span>                              <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">controlleraz</span>       <span class="p">|</span>                                        <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">nova</span><span class="o">-</span><span class="s s-Atom">conductor</span>   <span class="p">|</span> <span class="nf">enabled</span> <span class="o">:-</span><span class="p">)</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">14</span><span class="nv">T19</span><span class="s s-Atom">:</span><span class="mi">08</span><span class="s s-Atom">:</span><span class="mf">16.000000</span> <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">nova</span><span class="o">-</span><span class="s s-Atom">consoleauth</span> <span class="p">|</span> <span class="nf">enabled</span> <span class="o">:-</span><span class="p">)</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">14</span><span class="nv">T19</span><span class="s s-Atom">:</span><span class="mi">08</span><span class="s s-Atom">:</span><span class="mf">16.000000</span> <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">nova</span><span class="o">-</span><span class="s s-Atom">scheduler</span>   <span class="p">|</span> <span class="nf">enabled</span> <span class="o">:-</span><span class="p">)</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">14</span><span class="nv">T19</span><span class="s s-Atom">:</span><span class="mi">08</span><span class="s s-Atom">:</span><span class="mf">16.000000</span> <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">nova</span><span class="o">-</span><span class="s s-Atom">cert</span>        <span class="p">|</span> <span class="nf">enabled</span> <span class="o">:-</span><span class="p">)</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">14</span><span class="nv">T19</span><span class="s s-Atom">:</span><span class="mi">08</span><span class="s s-Atom">:</span><span class="mf">13.000000</span> <span class="p">|</span>
<span class="p">|</span> <span class="s s-Atom">az2</span>                   <span class="p">|</span> <span class="s s-Atom">available</span>                              <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">compute2az</span>         <span class="p">|</span>                                        <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">nova</span><span class="o">-</span><span class="s s-Atom">compute</span>     <span class="p">|</span> <span class="nf">enabled</span> <span class="o">:-</span><span class="p">)</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">14</span><span class="nv">T19</span><span class="s s-Atom">:</span><span class="mi">08</span><span class="s s-Atom">:</span><span class="mf">12.000000</span> <span class="p">|</span>
<span class="p">|</span> <span class="s s-Atom">az1</span>                   <span class="p">|</span> <span class="s s-Atom">available</span>                              <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">compute1az</span>         <span class="p">|</span>                                        <span class="p">|</span>
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span><span class="o">-</span> <span class="s s-Atom">nova</span><span class="o">-</span><span class="s s-Atom">compute</span>     <span class="p">|</span> <span class="nf">enabled</span> <span class="o">:-</span><span class="p">)</span> <span class="mi">2016</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">14</span><span class="nv">T19</span><span class="s s-Atom">:</span><span class="mi">08</span><span class="s s-Atom">:</span><span class="mf">12.000000</span> <span class="p">|</span>
<span class="s s-Atom">+-----------------------+----------------------------------------+</span>
</pre></div>


<p>Other method you can use:</p>
<div class="highlight"><pre><span></span># nova service-list
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host         | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-consoleauth | controlleraz | internal | enabled | up    | 2016-01-14T19:54:36.000000 | -               |
| 2  | nova-scheduler   | controlleraz | internal | enabled | up    | 2016-01-14T19:54:36.000000 | -               |
| 3  | nova-conductor   | controlleraz | internal | enabled | up    | 2016-01-14T19:54:35.000000 | -               |
| 4  | nova-cert        | controlleraz | internal | enabled | up    | 2016-01-14T19:54:33.000000 | -               |
| 5  | nova-compute     | compute2az   | az2      | enabled | up    | 2016-01-14T19:54:32.000000 | -               |
| 6  | nova-compute     | compute1az   | az1      | enabled | up    | 2016-01-14T19:54:32.000000 | -               |
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
</pre></div>


<p>Launch two instances using <code>"--availability-zone AZ</code>" option, you can
even select the compute node to use, just use
<code>"--availability-zone AZ:COMPUTE_NODE</code>".</p>
<div class="highlight"><pre><span></span># nova boot --flavor m1.tiny --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 --availability-zone az1 instanceaz1
# nova boot --flavor m1.tiny --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 --availability-zone az2 instanceaz2
</pre></div>


<p>Ensure the instances are running in the desired Availability Zone.</p>
<div class="highlight"><pre><span></span># nova show instanceaz1 | grep OS-EXT-AZ | awk &#39;{print$2&quot;:&quot;$4}&#39;
OS-EXT-AZ:availability_zone:az1
# nova show instanceaz2 | grep OS-EXT-AZ | awk &#39;{print$2&quot;:&quot;$4}&#39;
OS-EXT-AZ:availability_zone:az2
</pre></div>


<p>List Glance images.</p>
<div class="highlight"><pre><span></span># glance image-list
+--------------------------------------+----------+
| ID                                   | Name     |
+--------------------------------------+----------+
| a6d7a606-f725-480a-9b1b-7b3ae39b93d4 | cirros   |
| a6540d72-dff7-4fb1-bc64-a8ea69e65178 | imageaz1 |
| 9c7e2d55-0b96-43e2-9231-88e426edb350 | imageaz2 |
+--------------------------------------+----------+
</pre></div>


<p>Update the images with custom properties, i use <code>"availability_zone"</code>
because is the default meta parameter a Host Aggregate owns when is
inside Availability Zones.</p>
<div class="highlight"><pre><span></span># glance image-update --property availability_zone=az1 a6540d72-dff7-4fb1-bc64-a8ea69e65178
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| availability_zone | az1                                  |
| checksum          | 133eae9fb1c98f45894a4e60d8736619     |
| container_format  | bare                                 |
| created_at        | 2016-01-14T19:59:04Z                 |
| disk_format       | qcow2                                |
| id                | a6540d72-dff7-4fb1-bc64-a8ea69e65178 |
| min_disk          | 0                                    |
| min_ram           | 0                                    |
| name              | imageaz1                             |
| owner             | 0571c6769c3f46acb195eeb01b87ae38     |
| protected         | False                                |
| size              | 13200896                             |
| status            | active                               |
| tags              | []                                   |
| updated_at        | 2016-01-14T20:13:05Z                 |
| virtual_size      | None                                 |
| visibility        | private                              |
+-------------------+--------------------------------------+
# glance image-update --property availability_zone=az2 9c7e2d55-0b96-43e2-9231-88e426edb350
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| availability_zone | az2                                  |
| checksum          | 133eae9fb1c98f45894a4e60d8736619     |
| container_format  | bare                                 |
| created_at        | 2016-01-14T19:59:10Z                 |
| disk_format       | qcow2                                |
| id                | 9c7e2d55-0b96-43e2-9231-88e426edb350 |
| min_disk          | 0                                    |
| min_ram           | 0                                    |
| name              | imageaz2                             |
| owner             | 0571c6769c3f46acb195eeb01b87ae38     |
| protected         | False                                |
| size              | 13200896                             |
| status            | active                               |
| tags              | []                                   |
| updated_at        | 2016-01-14T20:13:27Z                 |
| virtual_size      | None                                 |
| visibility        | private                              |
+-------------------+--------------------------------------+
</pre></div>


<p>Boot two instances, now we use images with custom properties, those
properties will map to Availability Zones(you can use other type of
parameters mapping to Host Aggregates characteristics).</p>
<div class="highlight"><pre><span></span># nova boot --flavor m1.tiny --image imageaz1 --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceimageaz1
# nova boot --flavor m1.tiny --image imageaz2 --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceimageaz2
</pre></div>


<p>Ensure the instances booted in the desired Availability Zone.</p>
<div class="highlight"><pre><span></span># nova show instanceimageaz1 | grep OS-EXT-AZ | awk &#39;{print$2&quot;:&quot;$4}&#39;
OS-EXT-AZ:availability_zone:az1
# nova show instanceimageaz2 | grep OS-EXT-AZ | awk &#39;{print$2&quot;:&quot;$4}&#39;
OS-EXT-AZ:availability_zone:az2
</pre></div>


<p>Other method to launch instances is with parameters in flavors.<br>
Create two flavors.</p>
<div class="highlight"><pre><span></span># nova flavor-create --is-public true flavoraz1 6 512 1 1
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 7  | flavoraz1 | 512       | 1    | 0         |      | 1     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
# nova flavor-create --is-public true flavoraz2 7 512 1 1
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 8  | flavoraz2 | 512       | 1    | 0         |      | 1     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
</pre></div>


<p>Add metadata to a Host Aggregate with some characteristic property as
can be fast HD or cheap HW.</p>
<div class="highlight"><pre><span></span># nova aggregate-set-metadata az1-ag fast=true
Metadata has been successfully updated for aggregate 2.
+----+--------+-------------------+--------------+--------------------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                             |
+----+--------+-------------------+--------------+--------------------------------------+
| 2  | az1-ag | az1               | &#39;compute1az&#39; | &#39;availability_zone=az1&#39;, &#39;fast=true&#39; |
+----+--------+-------------------+--------------+--------------------------------------+
# nova aggregate-set-metadata az2-ag cheap=true
Metadata has been successfully updated for aggregate 3.
+----+--------+-------------------+--------------+---------------------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                              |
+----+--------+-------------------+--------------+---------------------------------------+
| 3  | az2-ag | az2               | &#39;compute2az&#39; | &#39;availability_zone=az2&#39;, &#39;cheap=true&#39; |
+----+--------+-------------------+--------------+---------------------------------------+
</pre></div>


<p>Update the previous created flavors with the associated metadata key
with the Host Aggregate.</p>
<div class="highlight"><pre><span></span># nova flavor-key flavoraz1 set  aggregate_instance_extra_specs:fast=true
# nova flavor-key flavoraz2 set  aggregate_instance_extra_specs:cheap=true
</pre></div>


<p>Ensure, the properties are properly created.</p>
<div class="highlight"><pre><span></span># nova flavor-show 7 | grep fast | awk &#39;{print$4$5}&#39;
{&quot;aggregate_instance_extra_specs:fast&quot;:&quot;true&quot;}
# nova flavor-show 8 | grep cheap | awk &#39;{print$4$5}&#39;
{&quot;aggregate_instance_extra_specs:cheap&quot;:&quot;true&quot;}
</pre></div>


<p>By default, Nova Scheduler don't allow filtering by extra Specs inserted
in flavors or images.<br>
First, ensure the following scheduler filters are allowed in Control
nodes.</p>
<div class="highlight"><pre><span></span># egrep ^scheduler_default_filters /etc/nova/nova.conf 
scheduler_default_filters=AggregateInstanceExtraSpecsFilter,RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter
</pre></div>


<p>If a change has been done in nova.conf file, restart nova services</p>
<div class="highlight"><pre><span></span># openstack-service restart nova
</pre></div>


<p>Boot another two instaces, now using custom flavors</p>
<div class="highlight"><pre><span></span># nova boot --flavor flavoraz1 --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceflavoraz1
# nova boot --flavor flavoraz2 --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceflavoraz2
</pre></div>


<p>Check where the instances are running.</p>
<div class="highlight"><pre><span></span># nova show instanceflavoraz1 | grep OS-EXT-AZ | awk &#39;{print$2&quot;:&quot;$4}&#39;
OS-EXT-AZ:availability_zone:az1
# nova show instanceflavoraz2 | grep OS-EXT-AZ | awk &#39;{print$2&quot;:&quot;$4}&#39;
OS-EXT-AZ:availability_zone:az2
</pre></div>


<p>That's all for now<br>
Hope this guide helps.<br>
Regards</p>
                <div class="clear"></div>

                <div class="info">
                    <a href="https://egonzalez90.github.io/openstack-segregation-with-availability-zones-and-host-aggregates.html">posted at 21:34</a>
                    &nbsp;&middot;&nbsp;<a href="https://egonzalez90.github.io/category/openstack.html" rel="tag">OpenStack</a>
                    &nbsp;&middot;
                    &nbsp;<a href="https://egonzalez90.github.io/tag/availability-zones.html" class="tags">availability zones</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/flavor.html" class="tags">flavor</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/guide.html" class="tags">guide</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/host-aggregates.html" class="tags">host aggregates</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/image.html" class="tags">image</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/meta.html" class="tags">meta</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/nova.html" class="tags selected">nova</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/openstack.html" class="tags">openstack</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/scheduler.html" class="tags">scheduler</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/segregation.html" class="tags">segregation</a>
                    &nbsp;<a href="https://egonzalez90.github.io/tag/usage.html" class="tags">usage</a>
                </div>
		<a href="https://egonzalez90.github.io/openstack-segregation-with-availability-zones-and-host-aggregates.html#disqus_thread">Click to read and post comments</a>
            </article>

                <div class="clear"></div>
                <div class="pages">

                    <a href="https://egonzalez90.github.io/page/2" class="next_page">Next&nbsp;&rarr;</a>
                    <span>Page 1 of 4</span>
                </div>

            <div class="clear"></div>
            <footer>
                <p>
                <a href="https://github.com/jody-frankowski/blue-penguin">Blue Penguin</a> Theme
                &middot;
                Powered by <a href="http://getpelican.com">Pelican</a>
                &middot;
                <a href="https://egonzalez90.github.io/feeds/all.atom.xml" rel="alternate">Atom Feed</a>
            </footer>
        </div>
        <div class="clear"></div>
    </div>
</body>
</html>