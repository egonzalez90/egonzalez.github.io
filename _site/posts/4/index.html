<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>OpenStack things</title>
  <meta name="description" content="OpenStack, Docker, Ansible, Ceph, Linux">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://217.182.136.201:8080/posts/4/">
  
  
  <link rel="alternate" type="application/rss+xml" title="OpenStack things" href="http://217.182.136.201:8080/feed.xml">

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="egongu90">
  <meta name="twitter:title" content="OpenStack things">
  <meta name="twitter:description" content="OpenStack, Docker, Ansible, Ceph, Linux">
  
    <meta name="twitter:creator" content="egongu90">
  
  

  <script type="text/javascript">
  WebFontConfig = {
    google: { families: [ 'Bitter:400,700,400italic:latin' ] }
  };
  (function() {
    var wf = document.createElement('script');
    wf.src = ('https:' == document.location.protocol ? 'https' : 'http') +
      '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
    wf.type = 'text/javascript';
    wf.async = 'true';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(wf, s);
  })();
</script>

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">OpenStack things</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/archives/">Archives</a>
      
        
        <a class="page-link" href="https://github.com/yous/whiteglass">GitHub</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home">

  

  

  <ul class="post-list">
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/configure-neutron-dvr-openstack-liberty/">Configure Neutron DVR OpenStack Liberty</a>
          </h1>

          <p class="post-meta">Jan 27, 2016 • 
  
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/openstack/">OpenStack</a>
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>Distributed Virtual Routers aka DVR were created to avoid single point of failure on neutron nodes.
When using standard routers, all the traffic is passing out through Neutron servers. Inside network servers, router namespaces are created routing all traffic and NAT forwarding between instances and public networks. When a network node falls down, instance traffic will no longer be available until a new namespace is created and executed in another network node.
Distributed routers is a way to avoid the SPOF neutron nodes were. When using DVR, router namespaces, are directly created inside compute nodes where all instance and l3 traffic are routed.</p>

<p>If you want to know more about DVR check this awesome links:
<a href="http://blog.gampel.net/2014/12/openstack-neutron-distributed-virtual.html" target="_blank">http://blog.gampel.net/2014/12/openstack-neutron-distributed-virtual.html</a>
<a href="http://blog.gampel.net/2014/12/openstack-dvr2-floating-ips.html" target="_blank">http://blog.gampel.net/2014/12/openstack-dvr2-floating-ips.html</a>
<a href="http://blog.gampel.net/2015/01/openstack-DVR-SNAT.html" target="_blank">http://blog.gampel.net/2015/01/openstack-DVR-SNAT.html</a></p>

<p>A previous OpenStack Liberty installation is required, mine was done with RDO packstack.</p>

<p><strong><ins datetime="2016-01-27T18:47:58+00:00">Configure all Neutron Servers</ins></strong></p>

<p>Edit ml2 configuration file with the following:</p>

<pre>
# vi /etc/neutron/plugins/ml2/ml2_conf.ini

mechanism_drivers = openvswitch,l2population
type_drivers = flat,vlan,vxlan
tenant_network_types = vxlan
vni_ranges = 10:100
vxlan_group = 224.1.1.1
enable_security_group = True
</pre>
<p>Edit neutron configuration file, enable DVR and uncomment dvr_base_mac option</p>
<pre>
# vi /etc/neutron/neutron.conf

router_distributed = True
dvr_base_mac = fa:16:3f:00:00:00
</pre>
<p>Configure l3 agent to use dvr_snat</p>
<pre>
# vi /etc/neutron/l3_agent.ini

agent_mode = dvr_snat
</pre>
<p>Restart neutron server</p>
<pre>
systemctl restart neutron-server
</pre>
<p><strong><ins datetime="2016-01-27T18:47:58+00:00">Configure all Compute Nodes</ins></strong></p>

<p>Install ml2 package</p>
<pre>
yum install openstack-neutron-ml2
</pre>
<p>Edit openvswitch agent file as below:</p>
<pre>
# vi /etc/neutron/plugins/ml2/openvswitch_agent.ini 

l2_population = True
arp_responder = True
enable_distributed_routing = True
</pre>
<p>Enable DVR and select an interface driver to be used by l3 agent</p>
<pre>
# vi /etc/neutron/l3_agent.ini

interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
agent_mode = dvr
</pre>
<p>Edit ml2 configuration file as below:</p>
<pre>
# vi /etc/neutron/plugins/ml2/ml2_conf.ini

type_drivers = flat,vlan,vxlan
tenant_network_types = vxlan
mechanism_drivers = openvswitch,l2population
vni_ranges = 10:100
vxlan_group = 224.1.1.1
enable_security_group = True
</pre>
<p>Start and enable metadata agent in compute nodes</p>
<pre>
systemctl start neutron-l3-agent neutron-metadata-agent
systemctl enable neutron-l3-agent neutron-metadata-agent
</pre>
<p>Create an external bridge with an external IP associated on it</p>
<pre>
# vi /etc/sysconfig/network-scripts/ifcfg-br-ex

DEVICE=br-ex
DEVICETYPE=ovs
TYPE=OVSBridge
BOOTPROTO=static
IPADDR=192.168.100.4                                                          
NETMASK=255.255.255.0
GATEWAY=192.168.100.1
ONBOOT=yes
</pre>
<p>Modify an unused interface connected with the same network as the IP configured with br-ex, edit the interface to be used as OVS port by br-ex</p>
<pre>
# vi /etc/sysconfig/network-scripts/ifcfg-eth1
DEVICE=eth1
TYPE=OVSPort
DEVICETYPE=ovs
OVS_BRIDGE=br-ex
ONBOOT=yes
</pre>
<p>Restart network service to apply changes on the interfaces and openvswith-agent</p>
<pre>
systemctl restart network
systemctl restart neutron-openvswitch-agent
</pre>
<p>Create an external network and a subnet on it</p>
<pre>
neutron net-create external_network --provider:network_type flat --provider:physical_network extnet  --router:external --shared
neutron subnet-create --name public_subnet --enable_dhcp=False --allocation-pool=start=192.168.100.100,end=192.168.100.150 --gateway=192.168.100.1 external_network 192.168.100.0/24
</pre>
<p>Create a router and associate external network as router gateway</p>
<pre>
neutron router-create router1
neutron router-gateway-set router1 external_network
</pre>
<p>Create an internal network, a subnet and associate an interface to the router</p>
<pre>
neutron net-create private_network
neutron subnet-create --name private_subnet private_network 10.0.1.0/24
neutron router-interface-add router1 private_subnet
</pre>
<p>Boot 2 instances</p>
<pre>
nova boot --flavor m1.tiny --image cirros --nic net-id=154da7a8-fa49-415e-9d35-c840b144a8df test1
nova boot --flavor m1.tiny --image cirros --nic net-id=154da7a8-fa49-415e-9d35-c840b144a8df test2
</pre>
<p>Create 2 floating ips and associate it to instances</p>
<pre>
neutron floatingip-create external_network
neutron floatingip-create external_network
nova floating-ip-associate test1 192.168.100.101
nova floating-ip-associate test2 192.168.100.102
</pre>
<p>Test if all works as expected pinging floating ips</p>
<pre>
# ping 192.168.100.101
# ping 192.168.100.102
</pre>
<p>As you can see, in network nodes, a snat namespace is created</p>
<pre>
# sudo ip netns
qdhcp-154da7a8-fa49-415e-9d35-c840b144a8df
snat-77fef58a-6d0c-4e96-b4b6-5d8e81ebead3
</pre>
<p>In compute nodes, a fip namespace per instance with floating ip associated running on the compute node are created and a qrouter namespace are created.</p>
<pre>
# sudo ip netns
fip-4dfdabb0-d2d6-4d4a-8c00-84df834eec8b
qrouter-77fef58a-6d0c-4e96-b4b6-5d8e81ebead3
</pre>

<p>Best regards, Eduardo Gonzalez</p>

        </div>
        
          <p class="post-continue">
            <a href="/configure-neutron-dvr-openstack-liberty/">Read on &rarr;</a>
          </p>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/openstack-segregation-with-availability-zones-and-host-aggregates/">OpenStack segregation with Availability Zones and Host Aggregates</a>
          </h1>

          <p class="post-meta">Jan 14, 2016 • 
  
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/openstack/">OpenStack</a>
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>When a new OpenStack cloud born, usually all servers run over the same hardware and specifications, often, all servers are in the same building, room, rack, even a chassis when the cloud is in the first growth paces.</p>

<p>After a while, workloads increase and the current hardware is not enough to process that workloads. At this point, your hardware is old and new hardware is bought. This hardware has different storage disks, CPU, RAM and so on. You passed from 10’s of servers to 100’s. DataCenter racks, rooms and buildings are too small and the growing cloud needs redundancy between cities or countries.</p>

<p>OpenStack offers a few solutions for that purpose, called Regions, Cells, Availability Zones and Host Aggregates.
Now, we are going to focus on Availability Zones and Host Aggregates, which are the way to segregate computational workloads.</p>
<ul>
	<li>Host Aggregates:
<ul>
	<li>Host Aggregates represent a logical set of properties/characteristics a group of hosts owns in the form of metadata. Imagine some of your servers have SSD disks and the other ones SATA, you can map those properties SSD/SATA to a group of hosts, when a image or flavor with the metaparameter associated is launched, Nova Scheduler will filter the available hosts with the meta parameter value and boot the instance on hosts with the desired property. Host Aggregates are managed by OpenStack admins.</li>
</ul>
</li>
	<li>Availability Zones
<ul>
	<li>Availability Zones represent a logical partition of the infrastructure(not necessary but is the common use case) in the form of racks, rooms, buildings, etc. Customers can launch instances in the desired Availability Zone.</li>
</ul>
</li>
</ul>
<p>Usually, Host Aggregates are mapped to Availability Zones allowing customers to use the desired set of hardware or characteristics to boot instances.</p>

<p>At the end of this guide you will know how to:</p>
<ol>
	<li>
Create Availability Zones and Host Aggregates.</li>
	<li>
Adding hosts to Host Aggregates and Availability Zones.</li>
	<li>
Launch instances directly to Availability Zones.</li>
	<li>
Configure nova scheduler for Host Aggregates usage.</li>
	<li>
Configure Images and Flavors for scheduling to Host Aggregates.</li>
	<li>
Launch instances based on flavors and image parameters.</li>
</ol>
<p>Let’s start: \00/</p>

<p>Create two Host Aggregate called <code>"az1-ag"/"az2-ag"</code>, this command also, will create two Availability Zones called <code>"az1"/"az2"</code>.
By default, when a Host Aggregate is created with an Availability Zone, a metadata key called <code>"availability_zone=NAME_OF_AZ</code>” will be created.</p>

<pre>
# nova aggregate-create az1-ag az1
+----+--------+-------------------+-------+-------------------------+
| Id | Name   | Availability Zone | Hosts | Metadata                |
+----+--------+-------------------+-------+-------------------------+
| 2  | az1-ag | az1               |       | 'availability_zone=az1' |
+----+--------+-------------------+-------+-------------------------+
# nova aggregate-create az2-ag az2
+----+--------+-------------------+-------+-------------------------+
| Id | Name   | Availability Zone | Hosts | Metadata                |
+----+--------+-------------------+-------+-------------------------+
| 3  | az2-ag | az2               |       | 'availability_zone=az2' |
+----+--------+-------------------+-------+-------------------------+
</pre>
<p>Add one or more compute nodes to Host Aggregates.</p>
<pre>
# nova aggregate-add-host 2 compute1az
Host compute1az has been successfully added for aggregate 2 
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 2  | az1-ag | az1               | 'compute1az' | 'availability_zone=az1' |
+----+--------+-------------------+--------------+-------------------------+
# nova aggregate-add-host 3 compute2az
Host compute2az has been successfully added for aggregate 3 
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 3  | az2-ag | az2               | 'compute2az' | 'availability_zone=az2' |
+----+--------+-------------------+--------------+-------------------------+
</pre>
<p>Details about a Host Aggregate can be reviewed with:</p>
<pre>
# nova aggregate-details az1-ag
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 2  | az1-ag | az1               | 'compute1az' | 'availability_zone=az1' |
+----+--------+-------------------+--------------+-------------------------+
# nova aggregate-details az2-ag
+----+--------+-------------------+--------------+-------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                |
+----+--------+-------------------+--------------+-------------------------+
| 3  | az2-ag | az2               | 'compute2az' | 'availability_zone=az2' |
+----+--------+-------------------+--------------+-------------------------+
</pre>
<p>List Availability Zones and check status.</p>
<pre>
# nova availability-zone-list
+-----------------------+----------------------------------------+
| Name                  | Status                                 |
+-----------------------+----------------------------------------+
| internal              | available                              |
| |- controlleraz       |                                        |
| | |- nova-conductor   | enabled :-) 2016-01-14T19:08:16.000000 |
| | |- nova-consoleauth | enabled :-) 2016-01-14T19:08:16.000000 |
| | |- nova-scheduler   | enabled :-) 2016-01-14T19:08:16.000000 |
| | |- nova-cert        | enabled :-) 2016-01-14T19:08:13.000000 |
| az2                   | available                              |
| |- compute2az         |                                        |
| | |- nova-compute     | enabled :-) 2016-01-14T19:08:12.000000 |
| az1                   | available                              |
| |- compute1az         |                                        |
| | |- nova-compute     | enabled :-) 2016-01-14T19:08:12.000000 |
+-----------------------+----------------------------------------+
</pre>
<p>Other method you can use:</p>
<pre>
# nova service-list
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
| Id | Binary           | Host         | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
| 1  | nova-consoleauth | controlleraz | internal | enabled | up    | 2016-01-14T19:54:36.000000 | -               |
| 2  | nova-scheduler   | controlleraz | internal | enabled | up    | 2016-01-14T19:54:36.000000 | -               |
| 3  | nova-conductor   | controlleraz | internal | enabled | up    | 2016-01-14T19:54:35.000000 | -               |
| 4  | nova-cert        | controlleraz | internal | enabled | up    | 2016-01-14T19:54:33.000000 | -               |
| 5  | nova-compute     | compute2az   | az2      | enabled | up    | 2016-01-14T19:54:32.000000 | -               |
| 6  | nova-compute     | compute1az   | az1      | enabled | up    | 2016-01-14T19:54:32.000000 | -               |
+----+------------------+--------------+----------+---------+-------+----------------------------+-----------------+
</pre>
<p>Launch two instances using <code>"--availability-zone AZ</code>” option, you can even select the compute node to use, just use <code>"--availability-zone AZ:COMPUTE_NODE</code>”.</p>
<pre>
# nova boot --flavor m1.tiny --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 --availability-zone az1 instanceaz1
# nova boot --flavor m1.tiny --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 --availability-zone az2 instanceaz2
</pre>
<p>Ensure the instances are running in the desired Availability Zone.</p>
<pre>
# nova show instanceaz1 | grep OS-EXT-AZ | awk '{print$2":"$4}'
OS-EXT-AZ:availability_zone:az1
# nova show instanceaz2 | grep OS-EXT-AZ | awk '{print$2":"$4}'
OS-EXT-AZ:availability_zone:az2
</pre>
<p>List Glance images.</p>
<pre>
# glance image-list
+--------------------------------------+----------+
| ID                                   | Name     |
+--------------------------------------+----------+
| a6d7a606-f725-480a-9b1b-7b3ae39b93d4 | cirros   |
| a6540d72-dff7-4fb1-bc64-a8ea69e65178 | imageaz1 |
| 9c7e2d55-0b96-43e2-9231-88e426edb350 | imageaz2 |
+--------------------------------------+----------+
</pre>
<p>Update the images with custom properties, i use <code>"availability_zone"</code> because is the default meta parameter a Host Aggregate owns when is inside Availability Zones.</p>
<pre>
# glance image-update --property availability_zone=az1 a6540d72-dff7-4fb1-bc64-a8ea69e65178
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| availability_zone | az1                                  |
| checksum          | 133eae9fb1c98f45894a4e60d8736619     |
| container_format  | bare                                 |
| created_at        | 2016-01-14T19:59:04Z                 |
| disk_format       | qcow2                                |
| id                | a6540d72-dff7-4fb1-bc64-a8ea69e65178 |
| min_disk          | 0                                    |
| min_ram           | 0                                    |
| name              | imageaz1                             |
| owner             | 0571c6769c3f46acb195eeb01b87ae38     |
| protected         | False                                |
| size              | 13200896                             |
| status            | active                               |
| tags              | []                                   |
| updated_at        | 2016-01-14T20:13:05Z                 |
| virtual_size      | None                                 |
| visibility        | private                              |
+-------------------+--------------------------------------+
# glance image-update --property availability_zone=az2 9c7e2d55-0b96-43e2-9231-88e426edb350
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| availability_zone | az2                                  |
| checksum          | 133eae9fb1c98f45894a4e60d8736619     |
| container_format  | bare                                 |
| created_at        | 2016-01-14T19:59:10Z                 |
| disk_format       | qcow2                                |
| id                | 9c7e2d55-0b96-43e2-9231-88e426edb350 |
| min_disk          | 0                                    |
| min_ram           | 0                                    |
| name              | imageaz2                             |
| owner             | 0571c6769c3f46acb195eeb01b87ae38     |
| protected         | False                                |
| size              | 13200896                             |
| status            | active                               |
| tags              | []                                   |
| updated_at        | 2016-01-14T20:13:27Z                 |
| virtual_size      | None                                 |
| visibility        | private                              |
+-------------------+--------------------------------------+
</pre>
<p>Boot two instances, now we use images with custom properties, those properties will map to Availability Zones(you can use other type of parameters mapping to Host Aggregates characteristics).</p>
<pre>
# nova boot --flavor m1.tiny --image imageaz1 --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceimageaz1
# nova boot --flavor m1.tiny --image imageaz2 --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceimageaz2
</pre>
<p>Ensure the instances booted in the desired Availability Zone.</p>
<pre>
# nova show instanceimageaz1 | grep OS-EXT-AZ | awk '{print$2":"$4}'
OS-EXT-AZ:availability_zone:az1
# nova show instanceimageaz2 | grep OS-EXT-AZ | awk '{print$2":"$4}'
OS-EXT-AZ:availability_zone:az2
</pre>
<p>Other method to launch instances is with parameters in flavors.
Create two flavors.</p>
<pre>
# nova flavor-create --is-public true flavoraz1 6 512 1 1
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 7  | flavoraz1 | 512       | 1    | 0         |      | 1     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
# nova flavor-create --is-public true flavoraz2 7 512 1 1
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 8  | flavoraz2 | 512       | 1    | 0         |      | 1     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
</pre>
<p>Add metadata to a Host Aggregate with some characteristic property as can be fast HD or cheap HW.</p>
<pre>
# nova aggregate-set-metadata az1-ag fast=true
Metadata has been successfully updated for aggregate 2.
+----+--------+-------------------+--------------+--------------------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                             |
+----+--------+-------------------+--------------+--------------------------------------+
| 2  | az1-ag | az1               | 'compute1az' | 'availability_zone=az1', 'fast=true' |
+----+--------+-------------------+--------------+--------------------------------------+
# nova aggregate-set-metadata az2-ag cheap=true
Metadata has been successfully updated for aggregate 3.
+----+--------+-------------------+--------------+---------------------------------------+
| Id | Name   | Availability Zone | Hosts        | Metadata                              |
+----+--------+-------------------+--------------+---------------------------------------+
| 3  | az2-ag | az2               | 'compute2az' | 'availability_zone=az2', 'cheap=true' |
+----+--------+-------------------+--------------+---------------------------------------+
</pre>
<p>Update the previous created flavors with the associated metadata key with the Host Aggregate.</p>
<pre>
# nova flavor-key flavoraz1 set  aggregate_instance_extra_specs:fast=true
# nova flavor-key flavoraz2 set  aggregate_instance_extra_specs:cheap=true
</pre>
<p>Ensure, the properties are properly created.</p>
<pre>
# nova flavor-show 7 | grep fast | awk '{print$4$5}'
{"aggregate_instance_extra_specs:fast":"true"}
# nova flavor-show 8 | grep cheap | awk '{print$4$5}'
{"aggregate_instance_extra_specs:cheap":"true"}
</pre>
<p>By default, Nova Scheduler don’t allow filtering by extra Specs inserted in flavors or images.
First, ensure the following scheduler filters are allowed in Control nodes.</p>
<pre>
# egrep ^scheduler_default_filters /etc/nova/nova.conf 
scheduler_default_filters=AggregateInstanceExtraSpecsFilter,RetryFilter,AvailabilityZoneFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter
</pre>
<p>If a change has been done in nova.conf file, restart nova services</p>
<pre>
# openstack-service restart nova
</pre>
<p>Boot another two instaces, now using custom flavors</p>
<pre>
# nova boot --flavor flavoraz1 --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceflavoraz1
# nova boot --flavor flavoraz2 --image cirros --nic net-id=6d62149e-74d3-4e52-9813-53ad207309f4 instanceflavoraz2
</pre>
<p>Check where the instances are running.</p>
<pre>
# nova show instanceflavoraz1 | grep OS-EXT-AZ | awk '{print$2":"$4}'
OS-EXT-AZ:availability_zone:az1
# nova show instanceflavoraz2 | grep OS-EXT-AZ | awk '{print$2":"$4}'
OS-EXT-AZ:availability_zone:az2
</pre>

<p>That’s all for now
Hope this guide helps.
Regards</p>

        </div>
        
          <p class="post-continue">
            <a href="/openstack-segregation-with-availability-zones-and-host-aggregates/">Read on &rarr;</a>
          </p>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/nova-docker-driver/">Nova Docker driver</a>
          </h1>

          <p class="post-meta">Dec 23, 2015 • 
  
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/openstack/">OpenStack</a>
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>Cloud computing has evolved too fast over the last years, currently is a totally different thing as the 5 years ago cloud, today is a common thing listening words like containers, instances, microservices, queue messages on linkedin, twitter, etc.</p>

<p>OpenStack is not a lazy community, new capabilities are daily added to the OpenStack catalog reaching more users and business needs who are discovered at the several summits and meetups over the world. One of that needs is the capability to easy create and manage docker containers.
Now we have two main methods, directly launching instances as containers from nova driver or with heat/kubernetes/messos.
The second method is the one with more followers, but there are some projects which are using nova driver as Solum, for this reason i’m going to show you how to configure docker as nova driver.</p>

<p>The fist step is install docker on the compute nodes</p>
<pre>
curl -sSL https://get.docker.com/ | sh

+ sh -c 'sleep 3; yum -y -q install docker-engine'
advertencia:/var/cache/yum/x86_64/7/docker-main-repo/packages/docker-engine-selinux-1.9.1-1.el7.centos.noarch.rpm: EncabezadoV4 RSA/SHA512 Signature, ID de clave 2c52609d: NOKEY
No se ha instalado la llave pública de docker-engine-selinux-1.9.1-1.el7.centos.noarch.rpm
Importando llave GPG 0x2C52609D:
Usuarioid  : "Docker Release Tool (releasedocker) &lt;docker@docker.com&gt;"
Huella       : 5811 8e89 f3a9 1289 7c07 0adb f762 2157 2c52 609d
Desde      : https://yum.dockerproject.org/gpg
Full path required for exclude: net:[4026532228].
Full path required for exclude: net:[4026532228].
Full path required for exclude: net:[4026532285].
Full path required for exclude: net:[4026532285].
Full path required for exclude: net:[4026532228].
Full path required for exclude: net:[4026532228].
Full path required for exclude: net:[4026532285].
Full path required for exclude: net:[4026532285].
</pre>
<p>Add nova user to docker group, docker group will be created during docker installation</p>
<pre>
usermod -aG docker nova
</pre>
<p>Start docker service</p>
<pre>
sudo systemctl start docker
</pre>
<p>Test docker installation with the following command, a Hello from Docker message should be prompted</p>
<pre>
sudo docker run hello-world

Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
b901d36b6f2f: Pull complete
0a6ba66e537a: Pull complete
Digest: sha256:8be990ef2aeb16dbcb9271ddfe2610fa6658d13f6dfb8bc72074cc1ca36966a7
Status: Downloaded newer image for hello-world:latest

Hello from Docker.
This message shows that your installation appears to be working correctly.
</pre>
<p>Once docker runs in a proper way, enable docker service at boot</p>
<pre>
sudo systemctl enable docker
ln -s '/usr/lib/systemd/system/docker.service' '/etc/systemd/system/multi-user.target.wants/docker.service'
</pre>
<p>Give docker socket the apropiate permissions</p>
<pre>
chmod 666  /var/run/docker.sock
</pre>
<p>Restart nova-compute service</p>
<pre>
systemctl restart openstack-nova-compute
</pre>
<p>Install git and pip if not present on the system</p>
<pre>
sudo yum install -y git
sudo easy_install pip
</pre>
<p>Clone docker driver for nova from OpenStack repositories</p>
<pre>
git clone -b stable/liberty https://github.com/openstack/nova-docker
</pre>
<p>Install basic requirements</p>
<pre>
cd nova-docker
sudo  pip install -r requirements.txt
</pre>
<p>Install docker driver</p>
<pre>
python setup.py install
</pre>
<p>Edit nova.conf and allow docker driver as compute driver</p>
<pre>
vi /etc/nova/nova.conf
compute_driver=novadocker.virt.docker.DockerDriver
</pre>
<p>Create the following directory</p>
<pre>
mkdir /etc/nova/rootwrap.d
</pre>
<p>Create a file with the following content to allow setting networking in docker containers</p>
<pre>
vi /etc/nova/rootwrap.d/docker.filters

[Filters]
# nova/virt/docker/driver.py: 'ln', '-sf', '/var/run/netns/.*'
ln: CommandFilter, /bin/ln, root
</pre>
<p>Edit glance-api.conf and allow docker as container format</p>
<pre>
vi /etc/glance/glance-api.conf
container_formats=ami,ari,aki,bare,ovf,ova,docker
</pre>
<p>Restart glance-api to apply changes</p>
<pre>
systemctl restart openstack-glance-api
</pre>
<p>Pull a docker image, i use hipache as testing image</p>
<pre>
docker pull hipache

Using default tag: latest
latest: Pulling from library/hipache
0a85502c06c9: Pull complete
0998bf8fb9e9: Pull complete
a6785352b25c: Pull complete
e9ae3c220b23: Pull complete
84d61e35041c: Pull complete
0fd25fcc737a: Pull complete
c0af65e2f918: Pull complete
dc335e9e58f4: Pull complete
7245129ed8a4: Pull complete
52a015bc8761: Pull complete
d38065541924: Pull complete
0b8658d6c429: Pull complete
188468e0ae8d: Pull complete
741abf992884: Pull complete
Digest: sha256:7774cf9155a8cc83b6964c7ea0d655143c152debc6d11d4f6dfa918c7a7ea099
Status: Downloaded newer image for hipache:latest
</pre>
<p>Upload the image to glance</p>
<pre>
docker save hipache | openstack image create hipache --public --container-format docker --disk-format raw

+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | e93b7c1ddeb2d38419bf44aaf07cc811                     |
| container_format | docker                                               |
| created_at       | 2015-12-18T10:06:31Z                                 |
| disk_format      | raw                                                  |
| file             | /v2/images/7f05f7d6-88af-4d0f-adad-66ca025404fa/file |
| id               | 7f05f7d6-88af-4d0f-adad-66ca025404fa                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | hipache                                              |
| owner            | 74675bfffc3c4e1a9d9fb2f1388217d4                     |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 384304640                                            |
| status           | active                                               |
| updated_at       | 2015-12-18T10:07:03Z                                 |
| virtual_size     | None                                                 |
| visibility       | public                                               |
+------------------+------------------------------------------------------+
</pre>
<p>Once the image is active at glance, create a new instance, the instance won’t be a KVM virtual machine, now will be a docker container</p>
<pre>
nova boot --flavor m1.tiny --image hipache --nic net-id=a1aa6336-9ae2-4ffb-99f5-1b6d1130989c --key-name mykey test1
</pre>
<p>After a while, the instance should be in ACTIVE state</p>
<pre>
watch nova list
+--------------------------------------+-------+--------+------------+-------------+-----------------------------+
| ID                                   | Name  | Status | Task State | Power State | Networks                    |
+--------------------------------------+-------+--------+------------+-------------+-----------------------------+
| fb192405-4150-4c2d-98ad-316141f48cc5 | test1 | ACTIVE | -          | Running     | private_network=192.168.1.3 |
+--------------------------------------+-------+--------+------------+-------------+-----------------------------+
</pre>
<p>If all the steps worked fine, you can use docker as nova backend.
Regards</p>

        </div>
        
          <p class="post-continue">
            <a href="/nova-docker-driver/">Read on &rarr;</a>
          </p>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/murano-in-rdo-openstack-manual-installation/">Murano in RDO OpenStack &amp;#8211; Manual Installation</a>
          </h1>

          <p class="post-meta">Dec 14, 2015 • 
  
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/openstack/">OpenStack</a>
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p>Want to install and use Murano in a RDO OpenStack environment? Here are the steps to do it.</p>

<p>The first thing we need to do, is to know what is Murano:
Murano is an application catalog who gives the users the capacity to launch pre-configured s/instances/jobs/g with apps in an OpenStack infrastructure.
As the final user just select an application from a catalog with a minimal configuration, and Murano will take the role to orchestrate the background jobs(create instances, configure apps, connect networks, etc)
For more information about application catalog project refer to this site:
<a href="https://wiki.openstack.org/wiki/Murano/ApplicationCatalog" target="_blank">https://wiki.openstack.org/wiki/Murano/ApplicationCatalog</a></p>

<p>At this tutorial, i will use the following s/configurations/versions/g:</p>
<ul>
	<li>Centos 7.1</li>
	<li>RDO Liberty release</li>
	<li>Hosts installed with packstack/ML2 network</li>
</ul>
<p> </p>

<p>Let’s start installing some pre requisites</p>
<pre>
sudo yum install -y gcc python-setuptools python-devel git postgresql-devel libffi-devel openssl-devel
</pre>
<p>Install pip</p>
<pre>
sudo easy_install pip
</pre>
<p>Install tox and upgrade six</p>
<pre>
sudo pip install tox
sudo pip install --upgrade six
</pre>
<p>Create a database for murano</p>
<pre>
mysql -u root -p
CREATE DATABASE murano;
</pre>
<p>Create murano user at MySQL</p>
<pre>
GRANT ALL PRIVILEGES ON murano.* TO 'murano'@'localhost' IDENTIFIED BY 'MURANODB_PASS';
GRANT ALL PRIVILEGES ON murano.* TO 'murano'@'%' IDENTIFIED BY 'MURANODB_PASS';
</pre>
<p>Clone murano from liberty/stable branch</p>
<pre>
git clone -b stable/liberty git://git.openstack.org/openstack/murano
</pre>
<p>Install all requirements</p>
<pre>
cd ~/murano/
sudo  pip install -r requirements.txt
</pre>
<p>Install murano</p>
<pre>
sudo python setup.py install
</pre>
<p>Create sample configuration file</p>
<pre>
oslo-config-generator --config-file etc/oslo-config-generator/murano.conf
</pre>
<p>Create murano directory and copy the sample content on it</p>
<pre>
mkdir /etc/murano
cp ~/murano/etc/murano/* /etc/murano/
</pre>
<p>Rename sample configuration to murano.conf</p>
<pre>
mv /etc/murano/murano.conf.sample /etc/murano/murano.conf
</pre>
<p>Edit the configuration file like this, adjust the configuration as your environment needs.
<code>
vi /etc/murano/murano.conf
</code></p>
<pre>
[oslo_messaging_rabbit]

rabbit_host=RABBITMQ_IP
rabbit_port=5672
rabbit_hosts=RABBITMQ_IP:5672
rabbit_use_ssl=False
rabbit_userid=guest
rabbit_password=guest
rabbit_virtual_host=/
rabbit_ha_queues=False
rabbit_notification_exchange=openstack
rabbit_notification_topic=notifications

[database]
connection = mysql://murano:MURANODB_PASS@MYSQL_IP/murano

[keystone_authtoken]
auth_uri=http://KEYSTONE_IP:5000/v2.0
identity_uri=http://KEYSTONE_IP:35357
admin_user=murano
admin_password=MURANO_PASS
admin_tenant_name=services

[murano]
url = http://MURANO_IP:8082

[rabbitmq]

host=RABBITMQ_IP
login=guest
password=guest
virtual_host=/
</pre>
<p>Create murano user</p>
<pre>
openstack user create --password MURANO_PASS murano
</pre>
<p>Add murano user to services tenant with admin privileges</p>
<pre>
openstack role add --project services --user murano admin
</pre>
<p>Create a service for application-catalog</p>
<pre>
openstack service create --name muranoapi --description "Murano Project" application-catalog
</pre>
<p>Associate an endpoint to application-catalog service</p>
<pre>
openstack endpoint create --region RegionOne --publicurl 'http://MURANO_IP:8082/' --adminurl 'http://MURANO_IP:8082/' --internalurl 'http://http://MURANO_IP:8082/' MURANO_SERVICE_ID
</pre>
<p>Sync the database</p>
<pre>
murano-db-manage --config-file /etc/murano/murano.conf upgrade
</pre>
<p>Open a new terminal and start murano-api service</p>
<pre>
murano-api --config-file /etc/murano/murano.conf
</pre>
<p>Import base murano package</p>
<pre>
murano-manage --config-file /etc/murano/murano.conf import-package murano/meta/io.murano
</pre>
<p>In a new terminal, start murano-engine service</p>
<pre>
murano-engine --config-file /etc/murano/murano.conf
</pre>
<p>Clone stable liberty module for horizon</p>
<pre>
git clone -b stable/liberty git://git.openstack.org/openstack/murano-dashboard
</pre>
<p>Install base requirements</p>
<pre>
cd ~/murano-dashboard
pip install -r requirements.txt
</pre>
<p>Install murano-dashboard module</p>
<pre>
sudo python setup.py install
</pre>
<p>Enable murano-dashboard at horizon</p>
<pre>
cp muranodashboard/local/_50_murano.py /usr/share/openstack-dashboard/openstack_dashboard/enabled/
</pre>
<p>Restart apache to apply changes</p>
<pre>
systemctl restart httpd
</pre>
<p>Import ApacheHttpServer package</p>
<pre>
murano --murano-repo-url="http://storage.apps.openstack.org/" package-import io.murano.apps.apache.ApacheHttpServer
</pre>
<p>You can find more packages at: <a href="http://apps.openstack.org/#tab=murano-apps" target="_blank">http://apps.openstack.org/#tab=murano-apps</a></p>

<p>This will add a Debian image to glance image service, wait until the image is in active status</p>

<p>Create a file with the following content, modify the variables with your own needs
<code>
vi object_model_patch.json
</code></p>
<pre>
[
    { "op": "add", "path": "/-", "value":
        {
            "instance": {
                "availabilityZone": "nova",
                "name": "APP_NAME",
                "image": "GLANCE_IMAGE_ID",
                "keyname": "KEY_PAIR",
                "flavor": "FLAVOR",
                "assignFloatingIp": false,
                "?": {
                    "type": "io.murano.resources.LinuxMuranoInstance",
                    "id": "===id1==="
                }
            },
            "name": "ApacheHttpServer",
            "enablePHP": true,
            "?": {
                "type": "io.murano.apps.apache.ApacheHttpServer",
                "id": "===id2==="
            }
        }
    }
]
</pre>
<p>Create an environment</p>
<pre>murano environment-create --join-subnet-id SUBNET_ID ENVIRONMENT_NAME</pre>
<pre>
murano environment-create --join-subnet-id e2c5175a-d5bc-4eb7-91ba-67ac9120c64a test
+----------------------------------+------+---------------------+---------------------+
| ID                               | Name | Created             | Updated             |
+----------------------------------+------+---------------------+---------------------+
| 68a19d233d2d42459faf64d375d995e5 | test | 2015-12-11T13:09:57 | 2015-12-11T13:09:57 |
+----------------------------------+------+---------------------+---------------------+
</pre>
<p>Create a session for temporal working on the environment</p>
<pre>murano environment-session-create ENVIRONMENT_ID</pre>
<pre>murano environment-session-create 68a19d233d2d42459faf64d375d995e5
Created new session:
+----------+----------------------------------+
| Property | Value                            |
+----------+----------------------------------+
| id       | b0f5e39a9c4c419c9ee7fdb6c92c37a6 |
+----------+----------------------------------+
</pre>
<p>Add the file with the apps configuration</p>
<pre>murano environment-apps-edit --session-id SESSION_ID ENVIRONMENT_ID FILE_NAME</pre>
<pre>murano environment-apps-edit --session-id b0f5e39a9c4c419c9ee7fdb6c92c37a6 68a19d233d2d42459faf64d375d995e5 object_model_patch.json 
</pre>
<p>Deploy the environment</p>
<pre>murano environment-deploy ENVIRONMENT_ID --session-id SESSION_ID</pre>
<pre>murano environment-deploy 68a19d233d2d42459faf64d375d995e5 --session-id b0f5e39a9c4c419c9ee7fdb6c92c37a6
+-----------+-------------------------------------------------------------+
| Property  | Value                                                       |
+-----------+-------------------------------------------------------------+
| created   | 2015-12-11T13:09:57                                         |
| id        | 68a19d233d2d42459faf64d375d995e5                            |
| name      | test                                                        |
| services  | [                                                           |
|           |   {                                                         |
|           |     "instance": {                                           |
|           |       "availabilityZone": "nova",                           |
|           |       "name": "test",                                       |
|           |       "assignFloatingIp": false,                            |
|           |       "keyname": "",                                        |
|           |       "flavor": "twogb",                                    |
|           |       "image": "9049eb0c-081e-4d56-9413-72fdc6f8d8bf",      |
|           |       "?": {                                                |
|           |         "type": "io.murano.resources.LinuxMuranoInstance",  |
|           |         "id": "30f5a591a58a468fbf4d7ef4755e0512"            |
|           |       }                                                     |
|           |     },                                                      |
|           |     "name": "ApacheHttpServer",                             |
|           |     "enablePHP": true,                                      |
|           |     "?": {                                                  |
|           |       "status": "deploying",                                |
|           |       "type": "io.murano.apps.apache.ApacheHttpServer",     |
|           |       "id": "98b994565c634f7e97d5f365203ce222"              |
|           |     }                                                       |
|           |   }                                                         |
|           | ]                                                           |
| status    | deploying                                                   |
| tenant_id | 3a5d50fac9a3462fa4d76b8b84677c3f                            |
| updated   | 2015-12-11T13:09:57                                         |
| version   | 0                                                           |
+-----------+-------------------------------------------------------------+
</pre>
<p>Now, you can check at nova the building status of the instances</p>
<pre>nova list
+--------------------------------------+-----------------------------------------+--------+------------+-------------+----------+
| ID                                   | Name                                    | Status | Task State | Power State | Networks |
+--------------------------------------+-----------------------------------------+--------+------------+-------------+----------+
| a68cedfb-7b4c-47a6-96fb-6b64a85a8ca6 | murano-mmnpdii1ozz7r2-test-5np5cvfeoiyh | BUILD  | scheduling | NOSTATE     |          |
+--------------------------------------+-----------------------------------------+--------+------------+-------------+----------+
</pre>
<p>After a while, the instance is up and running</p>
<pre>nova list
+--------------------------------------+-----------------------------------------+--------+------------+-------------+------------------+
| ID                                   | Name                                    | Status | Task State | Power State | Networks         |
+--------------------------------------+-----------------------------------------+--------+------------+-------------+------------------+
| a68cedfb-7b4c-47a6-96fb-6b64a85a8ca6 | murano-mmnpdii1ozz7r2-test-5np5cvfeoiyh | ACTIVE | -          | Running     | private=10.0.0.8 |
+--------------------------------------+-----------------------------------------+--------+------------+-------------+------------------+
</pre>
<p>Once the instance is active, murano will configure the application inside, wait until the status is ready.</p>
<pre>murano environment-show f392de2004e24ff7b2a08f05df0599b8
+-----------+---------------------------------------------------------------+
| Property  | Value                                                         |
+-----------+---------------------------------------------------------------+
| created   | 2015-12-11T13:43:23                                           |
| id        | 68a19d233d2d42459faf64d375d995e5                              |
| name      | test                                                          |
| services  | [                                                             |
|           |   {                                                           |
|           |     "instance": {                                             |
|           |       "availabilityZone": "nova",                             |
|           |       "openstackId": "91615340-e1d3-428e-848f-38a762004d33",  |
|           |       "name": "test",                                         |
|           |       "securityGroupName": null,                              |
|           |       "image": "9049eb0c-081e-4d56-9413-72fdc6f8d8bf",        |
|           |       "assignFloatingIp": false,                              |
|           |       "floatingIpAddress": null,                              |
|           |       "keyname": "",                                          |
|           |       "?": {                                                  |
|           |         "classVersion": "0.0.0",                              |
|           |         "name": null,                                         |
|           |         "package": "io.murano",                               |
|           |         "type": "io.murano.resources.LinuxMuranoInstance",    |
|           |         "_actions": {},                                       |
|           |         "id": "30f5a591a58a468fbf4d7ef4755e0512"              |
|           |       },                                                      |
|           |       "ipAddresses": [                                        |
|           |         "10.0.0.8"                                            |
|           |       ],                                                      |
|           |       "flavor": "twogb",                                      |
|           |       "networks": {                                           |
|           |         "useFlatNetwork": false,                              |
|           |         "primaryNetwork": null,                               |
|           |         "useEnvironmentNetwork": true,                        |
|           |         "customNetworks": []                                  |
|           |       },                                                      |
|           |       "sharedIps": []                                         |
|           |     },                                                        |
|           |     "name": "ApacheHttpServer",                               |
|           |     "?": {                                                    |
|           |       "classVersion": "0.0.0",                                |
|           |       "status": "ready",                                      |
|           |       "name": null,                                           |
|           |       "package": "io.murano.apps.apache.ApacheHttpServer",    |
|           |       "type": "io.murano.apps.apache.ApacheHttpServer",       |
|           |       "_actions": {},                                         |
|           |       "id": "98b994565c634f7e97d5f365203ce222"                |
|           |     },                                                        |
|           |     "enablePHP": true                                         |
|           |   }                                                           |
|           | ]                                                             |
| status    | ready                                                         |
| tenant_id | 3a5d50fac9a3462fa4d76b8b84677c3f                              |
| updated   | 2015-12-11T13:47:35                                           |
| version   | 1                                                             |
+-----------+---------------------------------------------------------------+
</pre>

<p>That’s all you need to have up and running a Murano application catalog, for now there is no rpm package to ease the installation, so you need to install from source like we done.
A thing you can do, is create systemd files to manage murano services in a easier way.</p>

<p>Regards, Eduardo Gonzalez</p>

        </div>
        
          <p class="post-continue">
            <a href="/murano-in-rdo-openstack-manual-installation/">Read on &rarr;</a>
          </p>
        
      </li>
    
      
      

      <li>
        <header class="post-header">
          <h1 class="post-title">
            <a class="post-link" href="/ceph-radosgw-admin-ops-how-to-use-it/">Ceph RadosGW Admin Ops, how to use it</a>
          </h1>

          <p class="post-meta">Sep 8, 2015 • 
  
  
    
  
    
  
    
  
    
  
    
      <a href="/categories/openstack/">OpenStack</a>
    
  
    
  
    
  

</p>
        </header>

        <div class="post-content">
          <p><br />&lt;/br&gt;
Using RadosGW admin ops for the first time, can be a real headache , for this purpose i have made this post, where you will understand how to use this API.
Let’s start:</p>

<p>For issue a request through admin ops, you need to have a signature, this signature is make it signing a header.
The header must to be composed by the current date, the request type(GET/PUT/POST/DELETE) and the request itself.
This header must be signed by SSL including the admin ops secret on this signature.
Now , you can make a request.
Sometimes, the time is not the same as the radosgw node expect, you can hack on it changing the date=$(date) value with:
If your host has two hours more than the radosgw node, substract this two hours under $(( 10#$i-2)) variable, where 2 is the two hours to substract.</p>
<pre>
date=$(for i in $(date "+%H") ; do date "+%a, %d %b %Y $(( 10#$i-2 )):%M:%S +0000" ; done)
</pre>
<p>Examples:</p>

<p>Create a user named egonzalez:</p>

<pre>
#!/bin/bash
token=U2JCD4ZG4D1XJOI5XNF4 ## USER_TOKEN
secret=+IFgr7POzLWS0i3hQnC+dd3DOAZObHoY5NYm6m3b ## USER_SECRET
query=$1
name=$2
query3="&amp;uid="
query2=admin/user
query4="&amp;quota-type=user"
date=$(date)
header="PUT\n\n\n${date}\n/${query2}"
sig=$(echo -en ${header} | openssl sha1 -hmac ${secret} -binary | base64)
curl -v -H "Date: ${date}" -H "Authorization: AWS ${token}:${sig}" -L -X PUT "http://10.0.2.10/${query2}?format=json${query3}${query}&amp;display-name=${name}" -H "Host: 10.0.2.10"
##Change IPs with your own IPs
</pre>
<p>Output:</p>
<pre>
[ceph@adminnode scripts]$ sh createUser.sh egonzalez EgonzalezDescription
{"user_id":"egonzalez","display_name":"EgonzalezDescription","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"egonzalez","access_key":"24FUKCWD6BL9T08DQ2JA","secret_key":"mEQdhcrsqOy7q6Snvu8B5d5A2Ek9OezJH+khwYvX"}],"swift_keys":[],"caps":[]}
</pre>
<p>See egonzalez quotas</p>
<pre>
#!/bin/bash
token=U2JCD4ZG4D1XJOI5XNF4 ## USER_TOKEN
secret=+IFgr7POzLWS0i3hQnC+dd3DOAZObHoY5NYm6m3b ## USER_SECRET
query=$1
query3="&amp;uid="
query2=admin/user
query4="&amp;quota-type=user"
date=$(date)
header="GET\n\n\n${date}\n/${query2}"
sig=$(echo -en ${header} | openssl sha1 -hmac ${secret} -binary | base64)
curl -v -H "Date: ${date}" -H "Authorization: AWS ${token}:${sig}" -L -X GET "http://10.0.2.10/${query2}?quota${query3}${query}&amp;quota-type=user" -H "Host: 10.0.2.10"
##Change IPs with your own IPs
</pre>
<p>Output:</p>
<pre>
[ceph@adminnode scripts]$ sh getuserquota.sh egonzalez

{"enabled": true,"max_size_kb":1000,"max_objects":1000}Status: 200 OK
</pre>
<p>See egonzalez user information.</p>
<pre>
#!/bin/bash
token=U2JCD4ZG4D1XJOI5XNF4 ## USER_TOKEN
secret=+IFgr7POzLWS0i3hQnC+dd3DOAZObHoY5NYm6m3b ## USER_SECRET
query=$1
query3="&amp;uid="
query2=admin/user
date=$(date)
header="GET\n\n\n${date}\n/${query2}"
sig=$(echo -en ${header} | openssl sha1 -hmac ${secret} -binary | base64)
curl -v -H "Date: ${date}" -H "Authorization: AWS ${token}:${sig}" -L -X GET "http://10.0.2.10/${query2}?format=json${query3}${query}" -H "Host: 10.0.2.10"
##Change IPs with your own IPs
</pre>
<p>Output:</p>
<pre>
[ceph@adminnode scripts]$ sh userInfo.sh egonzalez
{"user_id":"egonzalez","display_name":"EgonzalezDescription","email":"","suspended":0,"max_buckets":1000,"subusers":[],"keys":[{"user":"egonzalez","access_key":"24FUKCWD6BL9T08DQ2JA","secret_key":"mEQdhcrsqOy7q6Snvu8B5d5A2Ek9OezJH+khwYvX"}],"swift_keys":[],"caps":[]}
</pre>
<p>When you really understand how admin ops works, is not as dificult to use it, just search at the official documentation and modify the desired values.</p>

<p>I hope this helps:</p>

<p>Regards, Eduardo.</p>

        </div>
        
          <p class="post-continue">
            <a href="/ceph-radosgw-admin-ops-how-to-use-it/">Read on &rarr;</a>
          </p>
        
      </li>
    
  </ul>

  
  <div class="pagination">
    
      <a class="previous" href="/posts/5/">&laquo; Older</a>
    

    
      <a class="next" href="/posts/3/">Newer &raquo;</a>
    
  </div>



</div>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy;  - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="http://217.182.136.201:8080/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
